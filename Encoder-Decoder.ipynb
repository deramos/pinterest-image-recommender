{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d42ac4da-03b1-49fa-832d-356819d3b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import cifar\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "197a4855-f2c7-427c-80ad-b83672f154b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channel, out_channel, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f78c4a3-0d49-44c8-9610-1543ba2f82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(*list(resnet50().children())[:-2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2452376-77e4-400e-b7db-a9000b854cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            UpsampleBlock(2048, 1024),\n",
    "            UpsampleBlock(1024, 512),\n",
    "            UpsampleBlock(512, 256),\n",
    "            UpsampleBlock(256, 64),\n",
    "            UpsampleBlock(64, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4556501e-ce0b-4ff9-85ed-7fe0505cfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0508831-d075-406f-bfea-207216bb62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e75e4fc-08c0-4b02-8bf9-bd28855bfe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 169001437/169001437 [05:02<00:00, 558857.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = cifar.CIFAR100(root='./data', train=True, transform=transforms, download=True)\n",
    "test_data = cifar.CIFAR100(root='./data', train=False, transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69b16748-ac0d-49d7-8b7b-fe9cdc4da374",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7362d9e7-f971-4d90-a750-733a550491d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed690ff8-c1e8-480c-95af-fd4188f98f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2acc58f1-7ab0-466d-97ff-7056e3c26d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fcbaea5-2e0d-464d-b5b6-3d656c7a88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e29f98d5-2d92-4770-8b6b-77816681ca23",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string expression part cannot include a backslash (166509508.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[57], line 26\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'Epoch: {epoch} \\n Train Loss: {train_loss[-1] \\n Val Loss: {val_loss[-1]')\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string expression part cannot include a backslash\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss, val_loss = [], []\n",
    "    \n",
    "    model.train()\n",
    "    for image, _ in train_loader:\n",
    "        image = image.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, image)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    for image, _ in test_loader:\n",
    "        image = image.to(device)\n",
    "        \n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, image)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch} Train Loss: {train_loss[-1] \\n Val Loss: {val_loss[-1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8922b8-374d-4102-8d44-86a034bb953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
