{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d42ac4da-03b1-49fa-832d-356819d3b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import cifar\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "197a4855-f2c7-427c-80ad-b83672f154b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channel, out_channel, kernel_size=2, stride=2),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upsample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f78c4a3-0d49-44c8-9610-1543ba2f82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(*list(resnet50().children())[:-2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2452376-77e4-400e-b7db-a9000b854cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            UpsampleBlock(2048, 1024),\n",
    "            UpsampleBlock(1024, 512),\n",
    "            UpsampleBlock(512, 256),\n",
    "            UpsampleBlock(256, 128)\n",
    "            UpsampleBlock(128, 64)\n",
    "            UpsampleBlock(64, 64)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4556501e-ce0b-4ff9-85ed-7fe0505cfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0508831-d075-406f-bfea-207216bb62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e75e4fc-08c0-4b02-8bf9-bd28855bfe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 169001437/169001437 [05:02<00:00, 558857.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = cifar.CIFAR100(root='./data', train=True, transform=transforms, download=True)\n",
    "test_data = cifar.CIFAR100(root='./data', train=False, transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69b16748-ac0d-49d7-8b7b-fe9cdc4da374",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed690ff8-c1e8-480c-95af-fd4188f98f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2acc58f1-7ab0-466d-97ff-7056e3c26d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f87180d-44d6-461d-9ee8-d6384c0bd96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sample = torch.rand([1, 3, 224, 224])\n",
    "image_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d131db3-d6a4-49c7-bb9f-2e94530e7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(image_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2326e3d-3e7e-4dbe-b3dc-04d538d1aa2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 112, 112])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fcbaea5-2e0d-464d-b5b6-3d656c7a88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ac1d6-2a01-49c7-ae00-85cdd84fea80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f98d5-2d92-4770-8b6b-77816681ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for image, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
